# -*- coding: utf-8 -*-
"""Copy of Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qkZ3n8NkJLQH7sEWd576tb1cZrSafwyM
"""

# ===========================
# Advanced Time Series Forecasting with Attention-based NN
# Single-file Colab-ready script
# Copy entire cell into Google Colab and run
# ===========================

# 0) Install & Imports
!pip install -q tensorflow numpy pandas matplotlib scikit-learn

import os, random, math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# reproducibility
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)
random.seed(SEED)

# 1) Synthetic multivariate dataset (changeable)
T = 1400
t = np.arange(T)

feat1 = 0.02*t + 8*np.sin(0.08*t) + np.random.normal(0, 0.8, T)
feat2 = 4*np.sin(0.03*t + 1.0) + np.random.normal(0, 0.6, T)
feat3 = np.cumsum(np.random.normal(0, 0.05, T)) + 2*np.sin(0.015*t)
target = 0.5*feat1 + 0.35*feat2 + 0.15*feat3 + np.random.normal(0, 0.5, T)

df = pd.DataFrame({
    'feature1': feat1,
    'feature2': feat2,
    'feature3': feat3,
    'target': target
})
print("Dataset created:", df.shape)
display(df.head())

# 2) Scaling & windowing
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(df.values)

SEQ_LEN = 36   # input length
FUTURE = 1     # predict 1 step ahead

def create_dataset(data, seq_len=SEQ_LEN, future=FUTURE):
    X, y = [], []
    for i in range(len(data) - seq_len - future + 1):
        X.append(data[i:i+seq_len, :])          # all features as input
        y.append(data[i+seq_len:i+seq_len+future, 3])  # target column index=3
    return np.array(X), np.array(y)

X, y = create_dataset(data_scaled)
print("X,y shapes:", X.shape, y.shape)

# Train/test split
train_ratio = 0.8
train_size = int(len(X) * train_ratio)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

print("Train/Test:", X_train.shape[0], X_test.shape[0])

# 3) Baseline LSTM
n_features = X.shape[2]

baseline = models.Sequential([
    layers.Input(shape=(SEQ_LEN, n_features)),
    layers.LSTM(64, return_sequences=False),
    layers.Dense(32, activation='relu'),
    layers.Dense(FUTURE, activation='linear')
])
baseline.compile(optimizer='adam', loss='mse', metrics=['mae'])
baseline.summary()

es = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)
rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)

print("\nTraining baseline LSTM...")
hist_baseline = baseline.fit(X_train, y_train,
                            validation_split=0.2,
                            epochs=40,
                            batch_size=32,
                            callbacks=[es, rlr],
                            verbose=2)

# 4) Attention layer (Bahdanau) + Encoder -> Context -> Dense decoder
class BahdanauAttention(tf.keras.layers.Layer):
    def __init__(self, units):
        super().__init__()
        self.W1 = layers.Dense(units)
        self.W2 = layers.Dense(units)
        self.V  = layers.Dense(1)
    def call(self, encoder_outputs, hidden_state):
        hidden_with_time_axis = tf.expand_dims(hidden_state, axis=1)  # (batch,1,units)
        score = self.V(tf.nn.tanh(self.W1(encoder_outputs) + self.W2(hidden_with_time_axis)))
        attention_weights = tf.nn.softmax(score, axis=1)  # (batch, seq_len, 1)
        context_vector = attention_weights * encoder_outputs
        context_vector = tf.reduce_sum(context_vector, axis=1)  # (batch, units)
        return context_vector, attention_weights

enc_units = 64
attn_units = 32

encoder_inputs = layers.Input(shape=(SEQ_LEN, n_features))
encoder_outputs, state_h, state_c = layers.LSTM(enc_units, return_sequences=True, return_state=True)(encoder_inputs)

attention = BahdanauAttention(attn_units)
context_vector, attention_weights = attention(encoder_outputs, state_h)

x = layers.Concatenate()([context_vector, state_h])
x = layers.Dense(64, activation='relu')(x)
decoder_output = layers.Dense(FUTURE, activation='linear', name='decoder_output')(x)

# Model that returns prediction + attention weights (for inspection)
attention_model = models.Model(inputs=encoder_inputs, outputs=[decoder_output, attention_weights])
# For training, compile a wrapper that returns only decoder_output
train_model = models.Model(inputs=encoder_inputs, outputs=decoder_output)
train_model.compile(optimizer='adam', loss='mse', metrics=['mae'])
attention_model.summary()
train_model.summary()

print("\nTraining attention-based model...")
hist_attn = train_model.fit(X_train, y_train,
                           validation_split=0.2,
                           epochs=60,
                           batch_size=32,
                           callbacks=[es, rlr],
                           verbose=2)

# 5) Predictions + Metrics
pred_base = baseline.predict(X_test).reshape(-1)
pred_att  = train_model.predict(X_test).reshape(-1)
y_test_flat = y_test.reshape(-1)

def get_metrics(true, pred):
    mae = mean_absolute_error(true, pred)
    rmse = math.sqrt(mean_squared_error(true, pred))
    return mae, rmse

mae_b, rmse_b = get_metrics(y_test_flat, pred_base)
mae_a, rmse_a = get_metrics(y_test_flat, pred_att)

print(f"\nBaseline MAE={mae_b:.6f}, RMSE={rmse_b:.6f}")
print(f"Attention MAE={mae_a:.6f}, RMSE={rmse_a:.6f}")

# 6) Plot sample region (scaled)
plt.figure(figsize=(12,5))
start = 30
end = start + 300
plt.plot(y_test_flat[start:end], label='Actual', linewidth=2)
plt.plot(pred_base[start:end], label='Baseline', linestyle='--')
plt.plot(pred_att[start:end], label='Attention', linestyle=':')
plt.legend(); plt.title('Test slice (scaled)'); plt.show()

# 7) Get attention weights for a sample & heatmap
sample_idx = 15
sample = X_test[sample_idx:sample_idx+1]
pred_val, attn_w = attention_model.predict(sample)
attn_w = attn_w.reshape(-1)  # seq_len

plt.figure(figsize=(10,3))
plt.bar(range(len(attn_w)), attn_w)
plt.title(f'Attention weights (test sample {sample_idx})'); plt.xlabel('timesteps'); plt.show()

# 8) Inverse transform to original scale (target only) - utility
def invert_target(scaled_values):
    arr = np.array(scaled_values).reshape(-1,1)
    filler = np.zeros((arr.shape[0], df.shape[1]-1))
    full = np.concatenate([filler[:, :3], arr], axis=1)
    inv = scaler.inverse_transform(full)[:, 3]
    return inv

inv_true = invert_target(y_test_flat[:200])
inv_base = invert_target(pred_base[:200])
inv_attn = invert_target(pred_att[:200])

plt.figure(figsize=(12,5))
plt.plot(inv_true, label='Actual (orig)')
plt.plot(inv_base, label='Baseline pred')
plt.plot(inv_attn, label='Attention pred')
plt.legend(); plt.title('First 200 test samples (original scale)'); plt.show()

# 9) Save models & figures
os.makedirs('models', exist_ok=True)
baseline.save('models/baseline_lstm.h5')
train_model.save('models/attention_model.h5')
print("Models saved: models/baseline_lstm.h5 , models/attention_model.h5")

# Save a CSV of predictions for report
out_df = pd.DataFrame({
    'actual_scaled': y_test_flat,
    'pred_baseline_scaled': pred_base,
    'pred_attention_scaled': pred_att
})
out_df.to_csv('predictions_scaled.csv', index=False)
print("Predictions saved to predictions_scaled.csv")

# ===========================
# END
# ===========================